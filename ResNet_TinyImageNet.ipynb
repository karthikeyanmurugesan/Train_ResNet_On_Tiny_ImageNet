{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignement4_SonuGiri_ResNet50_51_ValAccuracy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lilnm_RyBnAD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sonu Giri\n",
        "> contact: sonugiri1043@gmail.com\n",
        "\n",
        "- DataSet: Tiny ImageNet\n",
        "- Model: ResNet-50 ( Without Fully Connected layer )"
      ]
    },
    {
      "metadata": {
        "id": "3ic3Mc6ioXdm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tiny ImageNet dataset consists of 200 categories and each category has 500 of 64x64 size images in training set."
      ]
    },
    {
      "metadata": {
        "id": "lcZtlW9OyMQ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Tiny ImageNet DataSet"
      ]
    },
    {
      "metadata": {
        "id": "C4Mn6-kHncmV",
        "colab_type": "code",
        "outputId": "fe6a02d7-69da-4c2f-a012-1eb0971dba3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount( '/content/drive', force_remount=True )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RntLE9efqLIm",
        "colab_type": "code",
        "outputId": "cb27ac17-c9c1-43fa-f741-2f8399856659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MPRltIc4zcT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extract test and training data from Tiny ImageNet DataSet"
      ]
    },
    {
      "metadata": {
        "id": "7TUH7bu7n5ta",
        "colab_type": "code",
        "outputId": "7d59b53f-cf95-47e6-f78c-3942f488bcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import scipy.ndimage as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(nd.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "  \n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_data.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_data.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0.\n",
            "Use ``matplotlib.pyplot.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0.\n",
            "Use ``matplotlib.pyplot.imread`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished loading data, in 57.27811360359192 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "97x8o4cTHfxp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Shuffle training data"
      ]
    },
    {
      "metadata": {
        "id": "K2kPgxn_Hd4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shuffle_data(train_data, train_labels ):\n",
        "    size = len(train_data)\n",
        "    train_idx = np.arange(size)\n",
        "    np.random.shuffle(train_idx)\n",
        "\n",
        "    return train_data[train_idx], train_labels[train_idx]\n",
        "  \n",
        "train_data, train_labels = shuffle_data(train_data, train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfTt7mvT-3JG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Build Resnet Model"
      ]
    },
    {
      "metadata": {
        "id": "S9Mu_RNRBS-Z",
        "colab_type": "code",
        "outputId": "60eded54-6f07-418e-994d-4a81a4271e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import six\n",
        "from keras.models import Model\n",
        "from keras.layers import ( Input, Activation, Dense, Flatten )\n",
        "from keras.layers.convolutional import ( Conv2D, MaxPooling2D, AveragePooling2D )\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\" \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4 \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1,1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras 'Model'.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        " \n",
        "        out = Conv2D(filters=num_outputs, kernel_size=(1, 1),\n",
        "                              strides=(1,1),\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4),\n",
        "                              activation=\"softmax\")(pool2)\n",
        "        flatten1 = Flatten()(out)\n",
        "        model = Model(inputs=input, outputs=flatten1)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5vJNK1FwDszD",
        "colab_type": "code",
        "outputId": "0b898480-0ec6-4c68-cf97-91ced9809496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "csv_logger = CSVLogger('resnet50_tiny_ImageNet.csv')\n",
        "\n",
        "batch_size = 500\n",
        "nb_classes = 200\n",
        "nb_epoch = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "# The images are RGB\n",
        "img_channels = 3\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "X_train = train_data\n",
        "Y_train = train_labels\n",
        "X_test = test_data\n",
        "Y_test = test_labels\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# subtract mean and normalize\n",
        "mean_image = np.mean(X_train, axis=0)\n",
        "X_train -= mean_image\n",
        "X_test -= mean_image\n",
        "X_train /= 128.\n",
        "X_test /= 128.\n",
        "\n",
        "model = ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DAgstQeTDy_S",
        "colab_type": "code",
        "outputId": "adac8f54-9439-4828-8f7d-9a3c9fbe53ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6256
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 64)   9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 16, 16, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 256)  0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 256)  1024        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 256)  0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 256)  0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 128)    32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 128)    512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 128)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 512)    131584      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 512)    66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 512)    0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 128)    65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 512)    0           add_4[0][0]                      \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 512)    2048        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 512)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 512)    0           add_5[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 128)    65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 128)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 512)    66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 512)    0           add_6[0][0]                      \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 512)    2048        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 512)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 256)    131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 256)    1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 256)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 256)    590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 4, 4, 256)    1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 256)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 4, 4, 1024)   525312      add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 1024)   263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 1024)   0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 1024)   4096        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 4, 4, 256)    262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 4, 4, 256)    590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 256)    1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 256)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 4, 4, 1024)   263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 4, 4, 1024)   4096        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 4, 4, 256)    262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 4, 4, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 4, 4, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 4, 4, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 4, 4, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 4, 4, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 4, 4, 1024)   263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 4, 4, 1024)   4096        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 4, 4, 256)    262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 4, 4, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 4, 4, 256)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 4, 4, 256)    590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 4, 4, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 4, 4, 256)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 1024)   263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 4, 4, 1024)   4096        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 4, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 4, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 4, 4, 256)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 4, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 4, 4, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 4, 4, 256)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 4, 4, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 4, 4, 1024)   4096        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 4, 4, 256)    262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 256)    1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 4, 256)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 4, 4, 256)    590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 4, 256)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 1024)   263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 4, 4, 1024)   4096        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 1024)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 2, 2, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 2, 2, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 512)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 2, 2, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 2, 2, 512)    2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 512)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 2, 2, 2048)   2099200     add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 2, 2, 2048)   0           conv2d_47[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 2, 2, 2048)   8192        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 2, 2, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 2, 2, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 512)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 2, 2, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 2, 2, 512)    2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 512)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 2, 2, 2048)   8192        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 2, 2, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 2, 2, 512)    2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 512)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 2, 2, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 2, 2, 512)    2048        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 512)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 2, 2, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 2, 2, 2048)   8192        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 2, 2, 2048)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 1, 1, 200)    409800      average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 200)          0           conv2d_54[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,982,152\n",
            "Trainable params: 23,936,712\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gDs8h4hEIfgC",
        "colab_type": "code",
        "outputId": "51eb6f0a-a372-45d1-f063-5e0c69a6a05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Using real-time data augmentation.')\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "          featurewise_center=False,           # set input mean to 0 over the dataset\n",
        "          samplewise_center=False,            # set each sample mean to 0\n",
        "          featurewise_std_normalization=False,# divide inputs by std of the dataset\n",
        "          samplewise_std_normalization=False, # divide each input by its std\n",
        "          zca_whitening=False,                # apply ZCA whitening\n",
        "          rotation_range=0,                   # randomly rotate images in the range (degrees, 0 to 180)\n",
        "          width_shift_range=0.1,              # randomly shift images horizontally (fraction of total width)\n",
        "          height_shift_range=0.1,             # randomly shift images vertically (fraction of total height)\n",
        "          horizontal_flip=True,               # randomly flip images\n",
        "          vertical_flip=False )               # randomly flip images\n",
        "\n",
        "# Compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit( X_train )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q5A5FkcTKe4e",
        "colab_type": "code",
        "outputId": "ddb4a518-f4fd-4c3c-b86f-b95e91a3763a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epoch = 10 # epoch 1-10\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator( datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                     steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                     validation_data=(X_test, Y_test),\n",
        "                     epochs=nb_epoch, verbose=1, max_q_size=100,\n",
        "                     callbacks=[lr_reducer, early_stopper, csv_logger] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=200, validation_data=(array([[[..., epochs=10, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 313s 2s/step - loss: 7.8622 - acc: 0.1091 - val_loss: 6.5234 - val_acc: 0.1111\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 284s 1s/step - loss: 5.4329 - acc: 0.2009 - val_loss: 5.2347 - val_acc: 0.1820\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 282s 1s/step - loss: 4.6477 - acc: 0.2485 - val_loss: 4.6894 - val_acc: 0.2170\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 282s 1s/step - loss: 4.2260 - acc: 0.2819 - val_loss: 4.4114 - val_acc: 0.2402\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 281s 1s/step - loss: 3.9444 - acc: 0.3107 - val_loss: 4.2279 - val_acc: 0.2517\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 281s 1s/step - loss: 3.7360 - acc: 0.3331 - val_loss: 4.0793 - val_acc: 0.2785\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 283s 1s/step - loss: 3.5748 - acc: 0.3553 - val_loss: 4.1140 - val_acc: 0.2661\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 284s 1s/step - loss: 3.4538 - acc: 0.3708 - val_loss: 3.8720 - val_acc: 0.3028\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 286s 1s/step - loss: 3.3490 - acc: 0.3863 - val_loss: 3.7867 - val_acc: 0.3144\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 285s 1s/step - loss: 3.2449 - acc: 0.4043 - val_loss: 3.6907 - val_acc: 0.3242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0338b92c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "omUW3ElFEmXK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs_passed = 10\n",
        "model.save_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )\n",
        "model.save( 'custom_resent50_model.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHenqmhnxuwU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Returns a compiled model identical to the previous one\n",
        "model = load_model( 'custom_resent50_model.h5')\n",
        "model.load_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1L3-JiPuHQ5a",
        "colab_type": "code",
        "outputId": "6a3a3cb4-d6c5-4c53-eb70-c5b686fd633c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_epoch = 10 # epoch 11-20\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    epochs=nb_epoch, verbose=1, max_q_size=100,\n",
        "                    callbacks=[lr_reducer, early_stopper, csv_logger])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=200, validation_data=(array([[[..., epochs=10, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 311s 2s/step - loss: 3.2031 - acc: 0.4109 - val_loss: 3.6135 - val_acc: 0.3344\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 284s 1s/step - loss: 3.1008 - acc: 0.4286 - val_loss: 3.5681 - val_acc: 0.3448\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 283s 1s/step - loss: 3.0402 - acc: 0.4400 - val_loss: 3.5631 - val_acc: 0.3517\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 286s 1s/step - loss: 2.9875 - acc: 0.4492 - val_loss: 3.5427 - val_acc: 0.3522\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 284s 1s/step - loss: 2.9247 - acc: 0.4614 - val_loss: 3.5898 - val_acc: 0.3516\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 283s 1s/step - loss: 2.8781 - acc: 0.4735 - val_loss: 3.6709 - val_acc: 0.3428\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 283s 1s/step - loss: 2.8397 - acc: 0.4792 - val_loss: 3.3663 - val_acc: 0.3853\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 282s 1s/step - loss: 2.7899 - acc: 0.4911 - val_loss: 3.4387 - val_acc: 0.3875\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 284s 1s/step - loss: 2.7637 - acc: 0.4954 - val_loss: 3.5677 - val_acc: 0.3743\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 283s 1s/step - loss: 2.7335 - acc: 0.5033 - val_loss: 3.5918 - val_acc: 0.3686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01ace26470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "EgqYmAhyj26X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs_passed = 20\n",
        "model.save_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )\n",
        "model.save( 'custom_resent50_model.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qi7WYC_kFp1",
        "colab_type": "code",
        "outputId": "1de0f6a5-078b-4314-a3da-2d6381d3194a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "epochs_passed = 20\n",
        "\n",
        "# Returns a compiled model identical to the previous one\n",
        "model = load_model( 'custom_resent50_model.h5')\n",
        "model.load_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzJzQl3IkGm0",
        "colab_type": "code",
        "outputId": "54e403ef-15cc-4aca-ade2-539edc8ab896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_epoch = 10 # epoch 21-30\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    epochs=nb_epoch, verbose=1, max_q_size=100,\n",
        "                    callbacks=[lr_reducer, early_stopper, csv_logger])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=200, validation_data=(array([[[..., epochs=10, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 313s 2s/step - loss: 2.7222 - acc: 0.5083 - val_loss: 3.4446 - val_acc: 0.3883\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 280s 1s/step - loss: 2.6477 - acc: 0.5233 - val_loss: 3.5928 - val_acc: 0.3657\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 281s 1s/step - loss: 2.6144 - acc: 0.5319 - val_loss: 3.4228 - val_acc: 0.3854\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 278s 1s/step - loss: 2.5891 - acc: 0.5370 - val_loss: 3.4009 - val_acc: 0.4019\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 280s 1s/step - loss: 2.5640 - acc: 0.5431 - val_loss: 3.4203 - val_acc: 0.3932\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 281s 1s/step - loss: 2.5398 - acc: 0.5482 - val_loss: 3.5287 - val_acc: 0.3887\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 280s 1s/step - loss: 2.5110 - acc: 0.5564 - val_loss: 3.5288 - val_acc: 0.3833\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 280s 1s/step - loss: 2.4860 - acc: 0.5638 - val_loss: 3.3098 - val_acc: 0.4300\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 279s 1s/step - loss: 2.4649 - acc: 0.5680 - val_loss: 3.4218 - val_acc: 0.4083\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 278s 1s/step - loss: 2.4491 - acc: 0.5726 - val_loss: 3.4574 - val_acc: 0.4021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feba56be278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "WiuRvKmMKaKL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs_passed = 30\n",
        "model.save_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )\n",
        "model.save( 'custom_resent50_model.h5' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Zl7JjCMKmAL",
        "colab_type": "code",
        "outputId": "c027080b-6e02-4fba-8a0d-5497d6c8bfec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "epochs_passed = 30\n",
        "\n",
        "# Returns a compiled model identical to the previous one\n",
        "model = load_model( 'custom_resent50_model.h5')\n",
        "model.load_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ieskAuuQLCfL",
        "colab_type": "code",
        "outputId": "fe9a005c-1086-43c3-9eac-9566064cd5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_epoch = 20 # epoch 31-50\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    epochs=nb_epoch, verbose=1, max_q_size=100,\n",
        "                    callbacks=[lr_reducer, early_stopper, csv_logger])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=200, validation_data=(array([[[..., epochs=20, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "200/200 [==============================] - 312s 2s/step - loss: 2.4577 - acc: 0.5752 - val_loss: 3.3310 - val_acc: 0.4151\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 280s 1s/step - loss: 2.3981 - acc: 0.5879 - val_loss: 3.4938 - val_acc: 0.4039\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 278s 1s/step - loss: 2.3730 - acc: 0.5941 - val_loss: 3.5969 - val_acc: 0.3922\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 278s 1s/step - loss: 2.3490 - acc: 0.6011 - val_loss: 3.6004 - val_acc: 0.3967\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 280s 1s/step - loss: 2.3398 - acc: 0.6040 - val_loss: 3.4154 - val_acc: 0.4206\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 279s 1s/step - loss: 2.3191 - acc: 0.6106 - val_loss: 3.3694 - val_acc: 0.4399\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 280s 1s/step - loss: 1.9283 - acc: 0.7093 - val_loss: 2.9221 - val_acc: 0.5035\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 277s 1s/step - loss: 1.7692 - acc: 0.7434 - val_loss: 2.9753 - val_acc: 0.5000\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 269s 1s/step - loss: 1.6890 - acc: 0.7602 - val_loss: 2.9595 - val_acc: 0.5028\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 232s 1s/step - loss: 1.6167 - acc: 0.7748 - val_loss: 2.9868 - val_acc: 0.5057\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 232s 1s/step - loss: 1.5674 - acc: 0.7832 - val_loss: 3.0460 - val_acc: 0.4963\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 232s 1s/step - loss: 1.5219 - acc: 0.7915 - val_loss: 3.0250 - val_acc: 0.4962\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 232s 1s/step - loss: 1.3456 - acc: 0.8445 - val_loss: 2.9447 - val_acc: 0.5149\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.2760 - acc: 0.8623 - val_loss: 2.9518 - val_acc: 0.5126\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.2328 - acc: 0.8742 - val_loss: 2.9595 - val_acc: 0.5160\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.1964 - acc: 0.8817 - val_loss: 2.9875 - val_acc: 0.5123\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.1674 - acc: 0.8893 - val_loss: 3.0070 - val_acc: 0.5089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yzmwIe6gg2zT",
        "colab_type": "code",
        "outputId": "88e7d259-d6f0-48c7-d4a5-b65cac13f0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "epochs_passed = 47\n",
        "model.save_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )\n",
        "model.save( 'custom_resent50_model.h5' )\n",
        "print(\"Model and weights after %s epochs have been saved\" % epochs_passed )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model and weights after 47 epochs have been saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3L2Bky9OhJVn",
        "colab_type": "code",
        "outputId": "ef90c03e-38df-491b-b54a-788d94f4c3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epoch = 13 # epoch 47-60\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                    validation_data=(X_test, Y_test),\n",
        "                    epochs=nb_epoch, verbose=1, max_q_size=100,\n",
        "                    callbacks=[lr_reducer, early_stopper, csv_logger])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=200, validation_data=(array([[[..., epochs=13, verbose=1, callbacks=[<keras.ca..., max_queue_size=100)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/13\n",
            "200/200 [==============================] - 232s 1s/step - loss: 1.1088 - acc: 0.9068 - val_loss: 2.9980 - val_acc: 0.5161\n",
            "Epoch 2/13\n",
            "200/200 [==============================] - 232s 1s/step - loss: 1.0894 - acc: 0.9118 - val_loss: 3.0060 - val_acc: 0.5143\n",
            "Epoch 3/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0760 - acc: 0.9154 - val_loss: 3.0285 - val_acc: 0.5154\n",
            "Epoch 4/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0610 - acc: 0.9191 - val_loss: 3.0449 - val_acc: 0.5137\n",
            "Epoch 5/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0486 - acc: 0.9216 - val_loss: 3.0565 - val_acc: 0.5128\n",
            "Epoch 6/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0363 - acc: 0.9252 - val_loss: 3.0628 - val_acc: 0.5115\n",
            "Epoch 7/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0210 - acc: 0.9302 - val_loss: 3.0554 - val_acc: 0.5146\n",
            "Epoch 8/13\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.0124 - acc: 0.9320 - val_loss: 3.0582 - val_acc: 0.5125\n",
            "Epoch 9/13\n",
            "200/200 [==============================] - 234s 1s/step - loss: 1.0103 - acc: 0.9320 - val_loss: 3.0648 - val_acc: 0.5134\n",
            "Epoch 10/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0040 - acc: 0.9338 - val_loss: 3.0650 - val_acc: 0.5135\n",
            "Epoch 11/13\n",
            "200/200 [==============================] - 233s 1s/step - loss: 1.0023 - acc: 0.9339 - val_loss: 3.0657 - val_acc: 0.5135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e41c465c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "iVa1WfL3hTNi",
        "colab_type": "code",
        "outputId": "1fdfc6c1-813b-4427-fbe7-4a7869cbcf44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "epochs_passed = 60\n",
        "model.save_weights( 'model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )\n",
        "model.save( 'custom_resent50_model.h5' )\n",
        "print(\"Model and weights after %s epochs have been saved\" % epochs_passed )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model and weights after 60 epochs have been saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}